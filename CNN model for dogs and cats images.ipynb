{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36969823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eaba4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c963990d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential', 'layers': []}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46c7af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "059f992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Convolution2D(filters=32,\n",
    "                  kernel_size=(3,3),\n",
    "                  input_shape=(64,64,3)\n",
    "                 )\n",
    ")\n",
    "\n",
    "# We know that while feeding th image data to the model, the image size/no of pixels should be the same but from this dataset, we can see that there are random sizes. So, we use the input shape function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77c00264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential',\n",
       " 'layers': [{'module': 'keras.layers',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 64, 64, 3),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'conv2d_input'},\n",
       "   'registered_name': None},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'batch_input_shape': (None, 64, 64, 3),\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'groups': 1,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 64, 64, 3)}}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "348b6bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D  # more similar functions are MeanPooling,Average Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57b8c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    MaxPooling2D(pool_size = (2,2),\n",
    "                 )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "054d5165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential',\n",
       " 'layers': [{'module': 'keras.layers',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 64, 64, 3),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'conv2d_input'},\n",
       "   'registered_name': None},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'batch_input_shape': (None, 64, 64, 3),\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'groups': 1,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 64, 64, 3)}},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 62, 62, 32)}}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f110a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bfbefc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Flatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd695c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 31, 31, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30752)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 896 (3.50 KB)\n",
      "Trainable params: 896 (3.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "713ed1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7e1e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Dense(units=128,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ace98f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Dense(units=64,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9534e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Dense(units=32,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e87bb6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd2d26a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 31, 31, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30752)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3936384   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3947649 (15.06 MB)\n",
      "Trainable params: 3947649 (15.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# As you can see that the number of features which is going to get feed in the neural network as per calculated by flattening layer by converting entire data to 1D is total 30,752. i.e 30752 features we have for our dataset which our model has calculated.\n",
    "# But the number of recprds/images per class is onlt 4000 which may cause our model's accuracy to get degraded. So, its important to have a look on the features which will feeded to the neural network as well as the no of records for all those features. Common sense! \n",
    "# That's why we are using the data generator function of keras below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b57568bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter\n",
    "#tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b310ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64769149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a251cdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# This we are doing preprocessing on our image data.\n",
    "# As the dataset which we have downloaded contain very less images, so our model may get trained but will not be that accurate.\n",
    "# So, we just do some operations on the image and save the new image in the same location so that it adds to our dataset\n",
    "# We perform operations like rescaling it,zooming it,flipping it horizontally etc.\n",
    "# More information you will get on keras data generation official website\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'cnn_dataset/training_set/',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'cnn_dataset/test_set/',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "854b91be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7764540d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "250/250 [==============================] - 60s 233ms/step - loss: 0.6874 - accuracy: 0.5684 - val_loss: 0.6640 - val_accuracy: 0.6060\n",
      "Epoch 2/75\n",
      "250/250 [==============================] - 33s 133ms/step - loss: 0.6449 - accuracy: 0.6175 - val_loss: 0.6332 - val_accuracy: 0.6250\n",
      "Epoch 3/75\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.6201 - accuracy: 0.6505 - val_loss: 0.6815 - val_accuracy: 0.6105\n",
      "Epoch 4/75\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.6165 - accuracy: 0.6543 - val_loss: 0.6034 - val_accuracy: 0.6685\n",
      "Epoch 5/75\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.6056 - accuracy: 0.6629 - val_loss: 0.6342 - val_accuracy: 0.6585\n",
      "Epoch 6/75\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.5857 - accuracy: 0.6876 - val_loss: 0.5844 - val_accuracy: 0.6890\n",
      "Epoch 7/75\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.5737 - accuracy: 0.6988 - val_loss: 0.5828 - val_accuracy: 0.6865\n",
      "Epoch 8/75\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.5742 - accuracy: 0.6927 - val_loss: 0.6217 - val_accuracy: 0.6715\n",
      "Epoch 9/75\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.5512 - accuracy: 0.7140 - val_loss: 0.5953 - val_accuracy: 0.6855\n",
      "Epoch 10/75\n",
      "250/250 [==============================] - 30s 122ms/step - loss: 0.5415 - accuracy: 0.7194 - val_loss: 0.5886 - val_accuracy: 0.6980\n",
      "Epoch 11/75\n",
      "250/250 [==============================] - 31s 125ms/step - loss: 0.5255 - accuracy: 0.7355 - val_loss: 0.5938 - val_accuracy: 0.7015\n",
      "Epoch 12/75\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.5206 - accuracy: 0.7351 - val_loss: 0.5853 - val_accuracy: 0.7035\n",
      "Epoch 13/75\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.5106 - accuracy: 0.7445 - val_loss: 0.6624 - val_accuracy: 0.6815\n",
      "Epoch 14/75\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.4950 - accuracy: 0.7575 - val_loss: 0.6103 - val_accuracy: 0.7025\n",
      "Epoch 15/75\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.4914 - accuracy: 0.7577 - val_loss: 0.6117 - val_accuracy: 0.7020\n",
      "Epoch 16/75\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.4773 - accuracy: 0.7769 - val_loss: 0.5833 - val_accuracy: 0.7140\n",
      "Epoch 17/75\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.4659 - accuracy: 0.7711 - val_loss: 0.6959 - val_accuracy: 0.6620\n",
      "Epoch 18/75\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.4567 - accuracy: 0.7818 - val_loss: 0.5926 - val_accuracy: 0.7150\n",
      "Epoch 19/75\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.4459 - accuracy: 0.7871 - val_loss: 0.6512 - val_accuracy: 0.7030\n",
      "Epoch 20/75\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.4352 - accuracy: 0.7952 - val_loss: 0.6326 - val_accuracy: 0.7010\n",
      "Epoch 21/75\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.4268 - accuracy: 0.7972 - val_loss: 0.6727 - val_accuracy: 0.7055\n",
      "Epoch 22/75\n",
      "250/250 [==============================] - 31s 125ms/step - loss: 0.4220 - accuracy: 0.8054 - val_loss: 0.6365 - val_accuracy: 0.7065\n",
      "Epoch 23/75\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.3963 - accuracy: 0.8190 - val_loss: 0.6501 - val_accuracy: 0.7050\n",
      "Epoch 24/75\n",
      "250/250 [==============================] - 34s 136ms/step - loss: 0.3941 - accuracy: 0.8167 - val_loss: 0.6580 - val_accuracy: 0.7100\n",
      "Epoch 25/75\n",
      "250/250 [==============================] - 34s 134ms/step - loss: 0.3878 - accuracy: 0.8273 - val_loss: 0.7466 - val_accuracy: 0.7010\n",
      "Epoch 26/75\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.3727 - accuracy: 0.8329 - val_loss: 0.6394 - val_accuracy: 0.7150\n",
      "Epoch 27/75\n",
      "250/250 [==============================] - 34s 136ms/step - loss: 0.3495 - accuracy: 0.8481 - val_loss: 0.7248 - val_accuracy: 0.7050\n",
      "Epoch 28/75\n",
      "250/250 [==============================] - 33s 130ms/step - loss: 0.3586 - accuracy: 0.8385 - val_loss: 0.7254 - val_accuracy: 0.6965\n",
      "Epoch 29/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.3380 - accuracy: 0.8530 - val_loss: 0.7280 - val_accuracy: 0.6960\n",
      "Epoch 30/75\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.3445 - accuracy: 0.8499 - val_loss: 0.7073 - val_accuracy: 0.7080\n",
      "Epoch 31/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.3210 - accuracy: 0.8585 - val_loss: 0.7529 - val_accuracy: 0.7050\n",
      "Epoch 32/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.3093 - accuracy: 0.8660 - val_loss: 0.7537 - val_accuracy: 0.7140\n",
      "Epoch 33/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.3023 - accuracy: 0.8702 - val_loss: 0.7933 - val_accuracy: 0.7100\n",
      "Epoch 34/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.2951 - accuracy: 0.8735 - val_loss: 0.7648 - val_accuracy: 0.7080\n",
      "Epoch 35/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.2907 - accuracy: 0.8767 - val_loss: 0.7527 - val_accuracy: 0.7165\n",
      "Epoch 36/75\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 0.2849 - accuracy: 0.8770 - val_loss: 0.7704 - val_accuracy: 0.7185\n",
      "Epoch 37/75\n",
      "250/250 [==============================] - 31s 126ms/step - loss: 0.2866 - accuracy: 0.8788 - val_loss: 0.7695 - val_accuracy: 0.7115\n",
      "Epoch 38/75\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.2719 - accuracy: 0.8880 - val_loss: 0.8209 - val_accuracy: 0.7180\n",
      "Epoch 39/75\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.2626 - accuracy: 0.8878 - val_loss: 0.8327 - val_accuracy: 0.7155\n",
      "Epoch 40/75\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.2451 - accuracy: 0.8959 - val_loss: 0.8182 - val_accuracy: 0.7090\n",
      "Epoch 41/75\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.2501 - accuracy: 0.8959 - val_loss: 0.8920 - val_accuracy: 0.6990\n",
      "Epoch 42/75\n",
      "250/250 [==============================] - 31s 125ms/step - loss: 0.2412 - accuracy: 0.8954 - val_loss: 0.8613 - val_accuracy: 0.7115\n",
      "Epoch 43/75\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.2350 - accuracy: 0.9034 - val_loss: 0.8738 - val_accuracy: 0.7045\n",
      "Epoch 44/75\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 0.2209 - accuracy: 0.9103 - val_loss: 1.1050 - val_accuracy: 0.6940\n",
      "Epoch 45/75\n",
      "250/250 [==============================] - 33s 131ms/step - loss: 0.2288 - accuracy: 0.9026 - val_loss: 0.9290 - val_accuracy: 0.6970\n",
      "Epoch 46/75\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 0.2189 - accuracy: 0.9119 - val_loss: 0.8728 - val_accuracy: 0.7025\n",
      "Epoch 47/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.2183 - accuracy: 0.9095 - val_loss: 0.8827 - val_accuracy: 0.7015\n",
      "Epoch 48/75\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.2173 - accuracy: 0.9118 - val_loss: 0.9368 - val_accuracy: 0.7115\n",
      "Epoch 49/75\n",
      "250/250 [==============================] - 33s 132ms/step - loss: 0.2062 - accuracy: 0.9155 - val_loss: 0.9418 - val_accuracy: 0.7140\n",
      "Epoch 50/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.1921 - accuracy: 0.9221 - val_loss: 1.0201 - val_accuracy: 0.7250\n",
      "Epoch 51/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.1952 - accuracy: 0.9212 - val_loss: 1.0234 - val_accuracy: 0.7170\n",
      "Epoch 52/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.1925 - accuracy: 0.9233 - val_loss: 1.0083 - val_accuracy: 0.7040\n",
      "Epoch 53/75\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.1884 - accuracy: 0.9240 - val_loss: 1.0222 - val_accuracy: 0.7010\n",
      "Epoch 54/75\n",
      "250/250 [==============================] - 33s 131ms/step - loss: 0.1901 - accuracy: 0.9250 - val_loss: 1.0525 - val_accuracy: 0.7165\n",
      "Epoch 55/75\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 0.1775 - accuracy: 0.9314 - val_loss: 1.0680 - val_accuracy: 0.7050\n",
      "Epoch 56/75\n",
      "250/250 [==============================] - 33s 131ms/step - loss: 0.1826 - accuracy: 0.9266 - val_loss: 1.0125 - val_accuracy: 0.7085\n",
      "Epoch 57/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 32s 129ms/step - loss: 0.1676 - accuracy: 0.9320 - val_loss: 1.0807 - val_accuracy: 0.7105\n",
      "Epoch 58/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.1796 - accuracy: 0.9304 - val_loss: 1.0811 - val_accuracy: 0.7070\n",
      "Epoch 59/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.1572 - accuracy: 0.9362 - val_loss: 1.0955 - val_accuracy: 0.7200\n",
      "Epoch 60/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.1605 - accuracy: 0.9327 - val_loss: 1.1432 - val_accuracy: 0.7080\n",
      "Epoch 61/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.1631 - accuracy: 0.9371 - val_loss: 1.0915 - val_accuracy: 0.7065\n",
      "Epoch 62/75\n",
      "250/250 [==============================] - 33s 130ms/step - loss: 0.1537 - accuracy: 0.9419 - val_loss: 1.0558 - val_accuracy: 0.7215\n",
      "Epoch 63/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.1568 - accuracy: 0.9390 - val_loss: 1.0183 - val_accuracy: 0.7105\n",
      "Epoch 64/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.1449 - accuracy: 0.9451 - val_loss: 1.1108 - val_accuracy: 0.7100\n",
      "Epoch 65/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.1383 - accuracy: 0.9433 - val_loss: 1.0761 - val_accuracy: 0.7190\n",
      "Epoch 66/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.1461 - accuracy: 0.9429 - val_loss: 1.1526 - val_accuracy: 0.7130\n",
      "Epoch 67/75\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 0.1351 - accuracy: 0.9469 - val_loss: 1.1387 - val_accuracy: 0.7140\n",
      "Epoch 68/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.1471 - accuracy: 0.9427 - val_loss: 1.0596 - val_accuracy: 0.7255\n",
      "Epoch 69/75\n",
      "250/250 [==============================] - 33s 131ms/step - loss: 0.1384 - accuracy: 0.9481 - val_loss: 1.1302 - val_accuracy: 0.7155\n",
      "Epoch 70/75\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 0.1373 - accuracy: 0.9451 - val_loss: 1.0967 - val_accuracy: 0.7245\n",
      "Epoch 71/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.1367 - accuracy: 0.9455 - val_loss: 1.1201 - val_accuracy: 0.7190\n",
      "Epoch 72/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.1293 - accuracy: 0.9509 - val_loss: 1.3924 - val_accuracy: 0.7115\n",
      "Epoch 73/75\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.1266 - accuracy: 0.9520 - val_loss: 1.2070 - val_accuracy: 0.7105\n",
      "Epoch 74/75\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 0.1208 - accuracy: 0.9505 - val_loss: 1.2842 - val_accuracy: 0.7095\n",
      "Epoch 75/75\n",
      "250/250 [==============================] - 33s 131ms/step - loss: 0.1307 - accuracy: 0.9514 - val_loss: 1.2588 - val_accuracy: 0.6875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22b56227250>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "        train_generator,\n",
    "        epochs=75,\n",
    "        validation_data=validation_generator,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99a1e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"myimage.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69f29d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose = 0) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffdb842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da11ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('dog.jpg',target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9f1568",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8060ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourd = np.expand_dims(test_image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af75ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14ec897",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(fourd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37deee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65197e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if result[0][0] == 1.0:\n",
    "    print('cat')\n",
    "else:\n",
    "    print('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd65f10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
